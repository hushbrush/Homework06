{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QshK8s21WBrf"
   },
   "source": [
    "# Homework06\n",
    "\n",
    "Exercises to practice pandas, data analysis and regression\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Understand the effects of pre-processing data\n",
    "- Get familiar with the ML flow: encode -> normalize -> train -> evaluate\n",
    "- Understand the difference between regression and classification tasks\n",
    "- Build intuition for different regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Hf8SXUwWOho"
   },
   "source": [
    "### Setup\n",
    "\n",
    "Run the following 2 cells to import all necessary libraries and helpers for this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/PSAM-5020-2025S-A/5020-utils/raw/main/src/data_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from data_utils import object_from_json_url\n",
    "from data_utils import StandardScaler\n",
    "from data_utils import LinearRegression, SGDRegressor\n",
    "from data_utils import regression_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "\n",
    "Let's load up the full [ANSUR](https://www.openlab.psu.edu/ansur2/) dataset that we looked at briefly in [Week 02](https://github.com/DM-GY-9103-2024F-H/WK02).\n",
    "\n",
    "This is the dataset that has anthropometric information about U.S. Army personnel.\n",
    "\n",
    "#### WARNING\n",
    "\n",
    "Like we mentioned in class, this dataset is being used for these exercises due to the level of detail in the dataset and the rigorous process that was used in collecting the data.\n",
    "\n",
    "This is a very specific dataset and should not be used to draw general conclusions about people, bodies, or anything else that is not related to the distribution of physical features of U.S. Army personnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "ANSUR_FILE = \"https://raw.githubusercontent.com/PSAM-5020-2025S-A/5020-utils/main/datasets/json/ansur.json\"\n",
    "ansur_data = object_from_json_url(ANSUR_FILE)\n",
    "\n",
    "# Look at first 2 records\n",
    "ansur_data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested data\n",
    "\n",
    "This is that *nested* dataset from Week 02.\n",
    "\n",
    "# ü§î\n",
    "\n",
    "Let's load it into a `DataFrame` to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into DataFrame\n",
    "ansur_df = pd.DataFrame.from_records(ansur_data)\n",
    "ansur_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# üòìüôÑ\n",
    "\n",
    "That didn't work too well. We ended up with objects in our columns.\n",
    "\n",
    "Luckily, our `DataFrame` library has a function called [`json_normalize()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.json_normalize.html) that can help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into DataFrame\n",
    "ansur_df = pd.json_normalize(ansur_data)\n",
    "ansur_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better. `DataFrames` are magic.\n",
    "\n",
    "#### Data Exploration\n",
    "\n",
    "Before we start creating models, let's do a little bit of data analysis and get a feeling for the shapes, distributions and relationships of our data.\n",
    "\n",
    "1. Print `min`, `max` and `average` values for all of the features.\n",
    "2. Print `covariance` tables for `age`, `ear.length` and `head.circumference`.\n",
    "3. Plot `age`, `ear.length` and `head.circumference` versus the $1$ *feature* that is most correlated to each of them.\n",
    "\n",
    "Don't forget to *encode* and *normalize* the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work on Data Exploration here\n",
    "\n",
    "# Encode non-numerical features\n",
    "ansur_df['female'] = (ansur_df['gender'] == 'F').astype(int)\n",
    "ansur_df.drop(columns=['gender'], inplace=True)\n",
    "\n",
    "# 1. Print min, max, avg\n",
    "# ansur_df.describe()\n",
    "print(\"Min:\", ansur_df.min())\n",
    "print(\"Max:\", ansur_df.max())\n",
    "print(\"Av:\", ansur_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansur_df['female'] = (ansur_df['gender'] == 'F').astype(int)\n",
    "ansur_df.drop(columns=['gender'], inplace=True)\n",
    "print(\"Min:\", ansur_df.min())\n",
    "print(\"Max:\", ansur_df.max())\n",
    "print(\"Av:\", ansur_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "### Normalize all data\n",
    "\n",
    "ansur_scaler = StandardScaler()\n",
    "ansur_scaled = ansur_scaler.fit_transform(ansur_df)\n",
    "\n",
    "## 2. Print Covariances\n",
    "print(ansur_df.cov())\n",
    "\n",
    "## 3. Plot features most correlated to age, ear length and head circumference\n",
    "correlations_ansur=ansur_df.corr()\n",
    "print(correlations_ansur)\n",
    "\n",
    "\n",
    "#plotting the important ones now\n",
    "#age:\n",
    "plt.scatter( ansur_df[\"ear.length\"], ansur_df.age, marker='o', linestyle='', alpha=0.3)\n",
    "plt.xlabel(\"ear length \")\n",
    "plt.ylabel(\"age\")\n",
    "plt.show()\n",
    "\n",
    "#ear length\n",
    "plt.scatter(ansur_df.weight, ansur_df[\"ear.length\"], marker='o', linestyle='', alpha=0.3)\n",
    "plt.xlabel(\"Weight\")\n",
    "plt.ylabel(\"Ear Length\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#head circumference\n",
    "plt.scatter(ansur_df[\"head.height\"],ansur_df[\"head.circumference\"] ,  marker='o', linestyle='', alpha=0.3)\n",
    "plt.xlabel(\"head height\")\n",
    "plt.ylabel(\"head circumference\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Does anything stand out about these graphs? Or the correlations?<br>\n",
    "Are correlations symmetric? Does the feature most correlated to ear length also have ear length as its most correlated pair?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">Ear Length and weight definitely have a positive correlation to them, and head circumference and height definitely have a positive correlation.\n",
    "Age and ear length is not super correlated in the most direct way, which makes sense as well.\n",
    "Head height being correlated to circumference sounds like a sort of a circularity bias.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "\n",
    "Now, we want to create a regression model to predict `head.circumference` from the data.\n",
    "\n",
    "From our [Week 06](https://github.com/PSAM-5020-2025S-A/WK06) notebook, we can create a regression model by following these steps:\n",
    "\n",
    "1. Load dataset (done! üéâ)\n",
    "2. Encode label features as numbers (done! ‚ö°Ô∏è)\n",
    "3. Normalize the data (done! üçæ)\n",
    "4. Separate the outcome variable and the input features\n",
    "5. Create a regression model using all features\n",
    "6. Run model on training data and measure error\n",
    "7. Plot predictions and interpret results\n",
    "8. Run model on test data, measure error, plot predictions, interpret results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Work on Regression Model here\n",
    "\n",
    "## Separate outcome variable and input features\n",
    "#output\n",
    "headCircumference = ansur_df[\"head.circumference\"]\n",
    "\n",
    "#input\n",
    "features= ansur_df[[\"head.height\", \"weight\", \"span\"]]\n",
    "\n",
    "## Create a regression model\n",
    "ansur_model= LinearRegression()\n",
    "ansur_model.fit(features, headCircumference)\n",
    "\n",
    "## Measure error on training data\n",
    "prediction_scaled = ansur_model.predict(features)\n",
    "# Un-normalize the data\n",
    "\n",
    "predicted = ansur_scaler.inverse_transform(prediction_scaled)\n",
    "regression_error(ansur_df[\"head.circumference\"], predicted[\"head.circumference\"])\n",
    "\n",
    "## Plot predictions and interpret results\n",
    "\n",
    "plt.plot(ansur_df[\"head.circumference\"], predicted[\"head.circumference\"], marker='', color='r')\n",
    "plt.title(\"predicted vs original head circumference\")\n",
    "plt.xlabel(\"original\")\n",
    "plt.ylabel(\"predicted\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Test Data\n",
    "ANSUR_TEST_FILE = \"https://raw.githubusercontent.com/PSAM-5020-2025S-A/5020-utils/main/datasets/json/ansur-test.json\"\n",
    "\n",
    "ansur_test_data = object_from_json_url(ANSUR_TEST_FILE)\n",
    "ansur_test_df = pd.json_normalize(ansur_test_data)\n",
    "\n",
    "ansur_test_encoded_df = ansur_test_df.copy()\n",
    "\n",
    "g_vals = ansur_encoder.transform(ansur_test_df[[\"gender\"]].values)\n",
    "ansur_test_encoded_df[[\"gender\"]] = g_vals\n",
    "\n",
    "ansur_test_scaled_df = ansur_scaler.transform(ansur_test_encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "## Run model on test data\n",
    "\n",
    "## Measure error on test data\n",
    "\n",
    "## Plot predictions and interpret results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "How well does your model perform?<br>\n",
    "How could you improve it?<br>\n",
    "Are there ranges of circumferences that don't get predicted well?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
